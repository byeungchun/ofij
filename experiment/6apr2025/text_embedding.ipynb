{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import httpx\n",
    "import openai\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.path.expanduser('~'), 'data','ofij')\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "stmeta_file = os.path.join(base_dir,'stock_meta.feather')\n",
    "news_files = glob(os.path.join(base_dir, 'news*.feather'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnews = pd.read_feather(news_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntt_usiq_srno</th>\n",
       "      <th>news_ofer_entp_code</th>\n",
       "      <th>data_dt</th>\n",
       "      <th>data_tm</th>\n",
       "      <th>hts_pbnt_titl_cntt</th>\n",
       "      <th>news_lrdv_code</th>\n",
       "      <th>dorg</th>\n",
       "      <th>iscd1</th>\n",
       "      <th>kor_isnm1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024032100100098155</td>\n",
       "      <td>U</td>\n",
       "      <td>20240321</td>\n",
       "      <td>001000</td>\n",
       "      <td>[ê¸°ìì˜ ëˆˆ] ë²šê½ƒì—†ëŠ” ë²šê½ƒì¶•ì œ</td>\n",
       "      <td>39</td>\n",
       "      <td>ì„œìš¸ê²½ì œ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024032100090896253</td>\n",
       "      <td>2</td>\n",
       "      <td>20240321</td>\n",
       "      <td>000908</td>\n",
       "      <td>ì™¸ì‹ ë“¤,\"ì—”ë¹„ë””ì•„ ì  ìŠ¨í™©ì´ AIê³„ ìŠ¤í‹°ë¸Œ ì¡ìŠ¤\" í‰ê°€</td>\n",
       "      <td>04</td>\n",
       "      <td>í•œêµ­ê²½ì œì‹ ë¬¸</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024032100053623852</td>\n",
       "      <td>2</td>\n",
       "      <td>20240321</td>\n",
       "      <td>000536</td>\n",
       "      <td>ë² íŠ¸ë‚¨ GDP 3% íš¡ë ¹í•œ ë¶€ë™ì‚° ì¬ë²Œâ€¦ì‚¬í˜• êµ¬í˜•</td>\n",
       "      <td>09</td>\n",
       "      <td>í•œêµ­ê²½ì œì‹ ë¬¸</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024032100050072449</td>\n",
       "      <td>U</td>\n",
       "      <td>20240321</td>\n",
       "      <td>000500</td>\n",
       "      <td>[ì‚¬ì„¤] â€œì •ê·œì§ ê³¼ë³´í˜¸ì— ì¤‘ì¥ë…„ ê³ ìš© ë¶ˆì•ˆâ€Â·Â·Â·ë…¸ë™ ìœ ì—°í™” ì„œë‘˜ëŸ¬ì•¼</td>\n",
       "      <td>39</td>\n",
       "      <td>ì„œìš¸ê²½ì œ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024032100050059151</td>\n",
       "      <td>U</td>\n",
       "      <td>20240321</td>\n",
       "      <td>000500</td>\n",
       "      <td>[ì‚¬ì„¤] ì˜ëŒ€ë³„ ì •ì› í™•ì •, íŠ¹ìœ„ì—ì„œ í•„ìˆ˜?ì§€ì—­ ì˜ë£Œ ì •ìƒí™”ì— ë¨¸ë¦¬ ë§ëŒ€ë¼</td>\n",
       "      <td>39</td>\n",
       "      <td>ì„œìš¸ê²½ì œ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cntt_usiq_srno news_ofer_entp_code   data_dt data_tm  \\\n",
       "0  2024032100100098155                   U  20240321  001000   \n",
       "1  2024032100090896253                   2  20240321  000908   \n",
       "2  2024032100053623852                   2  20240321  000536   \n",
       "3  2024032100050072449                   U  20240321  000500   \n",
       "4  2024032100050059151                   U  20240321  000500   \n",
       "\n",
       "                          hts_pbnt_titl_cntt news_lrdv_code    dorg iscd1  \\\n",
       "0                          [ê¸°ìì˜ ëˆˆ] ë²šê½ƒì—†ëŠ” ë²šê½ƒì¶•ì œ             39    ì„œìš¸ê²½ì œ         \n",
       "1              ì™¸ì‹ ë“¤,\"ì—”ë¹„ë””ì•„ ì  ìŠ¨í™©ì´ AIê³„ ìŠ¤í‹°ë¸Œ ì¡ìŠ¤\" í‰ê°€             04  í•œêµ­ê²½ì œì‹ ë¬¸         \n",
       "2                ë² íŠ¸ë‚¨ GDP 3% íš¡ë ¹í•œ ë¶€ë™ì‚° ì¬ë²Œâ€¦ì‚¬í˜• êµ¬í˜•             09  í•œêµ­ê²½ì œì‹ ë¬¸         \n",
       "3    [ì‚¬ì„¤] â€œì •ê·œì§ ê³¼ë³´í˜¸ì— ì¤‘ì¥ë…„ ê³ ìš© ë¶ˆì•ˆâ€Â·Â·Â·ë…¸ë™ ìœ ì—°í™” ì„œë‘˜ëŸ¬ì•¼             39    ì„œìš¸ê²½ì œ         \n",
       "4  [ì‚¬ì„¤] ì˜ëŒ€ë³„ ì •ì› í™•ì •, íŠ¹ìœ„ì—ì„œ í•„ìˆ˜?ì§€ì—­ ì˜ë£Œ ì •ìƒí™”ì— ë¨¸ë¦¬ ë§ëŒ€ë¼             39    ì„œìš¸ê²½ì œ         \n",
       "\n",
       "  kor_isnm1  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342960, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10401, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews = dfnews.drop_duplicates()\n",
    "dfnews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['í•œê¸€ëª…', 'í‘œì¤€ì½”ë“œ', 'ë‹¨ì¶•ì½”ë“œ', 'ìƒì¥ì¼ì', 'ì‹œì¥êµ¬ë¶„', 'ì—…ì¢…ëŒ€ë¶„ë¥˜', 'ì—…ì¢…ì¤‘ë¶„ë¥˜', 'í‘œì¤€ì‚°ì—…ë¶„ë¥˜',\n",
       "       'ì•¡ë©´ê°€', 'ì‹œê°€ì´ì•¡(ì–µ ì›)', 'ë§¤ì¶œì•¡(ì–µ ì›)', 'ì˜ì—…ì´ìµ(ì–µ ì›)', 'ë‹¹ê¸°ìˆœì´ìµ(ì–µ ì›)', 'ROE(%)',\n",
       "       'ì „ì¼ì¢…ê°€(ì›)', 'ì‹ ìš©ê°€ëŠ¥', 'ì¦ê±°ê¸ˆë¹„ìœ¨(%)', 'KRXë°”ì´ì˜¤', 'ê´€ë¦¬ì¢…ëª©', 'ê±°ë˜ì •ì§€', 'ë¶ˆì„±ì‹¤ê³µì‹œ',\n",
       "       'ì´ìƒê¸‰ë“±'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmeta = pd.read_feather(stmeta_file)\n",
    "dfmeta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metarecs = []\n",
    "for i, rec in dfmeta.iterrows():\n",
    "    metarecs.append('; '.join([f'{metacol}: {rec[metacol]}' for metacol in ['í•œê¸€ëª…','ì—…ì¢…ëŒ€ë¶„ë¥˜','ì—…ì¢…ì¤‘ë¶„ë¥˜','í‘œì¤€ì‚°ì—…ë¶„ë¥˜']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í•œê¸€ëª…: ê²½ë°©; ì—…ì¢…ëŒ€ë¶„ë¥˜: ì‹œê°€ì´ì•¡ê·œëª¨ì¤‘; ì—…ì¢…ì¤‘ë¶„ë¥˜: ì„¬ìœ ,ì˜ë³µ; í‘œì¤€ì‚°ì—…ë¶„ë¥˜: ì¢…í•© ì†Œë§¤ì—…'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metarecs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "httpx_client= httpx.Client(verify=False) #, timeout=60)\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "client = OpenAI(http_client=httpx_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock meta sentence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "Using the provided stock metadata, generate a concise and informative sentence describing the stock.\n",
    "Your response must be a single sentence and must accurately reflect the given metadata.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_jsonl = []\n",
    "for i, row in enumerate(metarecs):\n",
    "    texts_jsonl.append({\n",
    "        'custom_id': str(i), \n",
    "        'method': 'POST',\n",
    "        'url': '/v1/chat/completions',\n",
    "        'body': {\n",
    "            'model':'gpt-4o-mini',\n",
    "            'messages':[{'role': 'system', 'content': system_message}, {'role':'user','content': row}], 'max_tokens':1000\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save texts_jsonl to file\n",
    "text_jsonfile = os.path.join(base_dir,'stock_meta.jsonl')\n",
    "with open(text_jsonfile, 'w', encoding='utf-8') as f:\n",
    "    for text in texts_jsonl:\n",
    "        jsonrec = json.dumps(text, ensure_ascii=False)\n",
    "        f.write(f'{jsonrec}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file = client.files.create(\n",
    "    file=open(text_jsonfile, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "batch_input_file_id = batch_input_file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = os.path.join(base_dir, 'stock_meta_response.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': '2',\n",
       " 'method': 'POST',\n",
       " 'url': '/v1/chat/completions',\n",
       " 'body': {'model': 'gpt-4o-mini',\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': '\\nUsing the provided stock metadata, generate a concise and informative sentence describing the stock.\\nYour response must be a single sentence and must accurately reflect the given metadata.\\n'},\n",
       "   {'role': 'user',\n",
       "    'content': 'í•œê¸€ëª…: ê²½ë°©; ì—…ì¢…ëŒ€ë¶„ë¥˜: ì‹œê°€ì´ì•¡ê·œëª¨ì¤‘; ì—…ì¢…ì¤‘ë¶„ë¥˜: ì„¬ìœ ,ì˜ë³µ; í‘œì¤€ì‚°ì—…ë¶„ë¥˜: ì¢…í•© ì†Œë§¤ì—…'}],\n",
       "  'max_tokens': 1000}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_jsonl[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification Batch ID: batch_67fa486e837081908513665ade19efec\n"
     ]
    }
   ],
   "source": [
    "# Create batch embedding request\n",
    "batch_embedding_obj = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"news articles sentiment classification\"\n",
    "    }\n",
    ")\n",
    "\n",
    "batch_id = batch_embedding_obj.id\n",
    "print(f\"classification Batch ID: {batch_embedding_obj.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_jsonl = []\n",
    "for i, row in dfnews.iterrows():\n",
    "    texts_jsonl.append({\n",
    "        'custom_id': str(i), \n",
    "        'method': 'POST',\n",
    "        'url': '/v1/embeddings',\n",
    "        'body': {\n",
    "            'input': row['hts_pbnt_titl_cntt'], \n",
    "            'model':'text-embedding-3-small',\n",
    "            'encoding_format': 'float'\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'custom_id': '0',\n",
       "  'method': 'POST',\n",
       "  'url': '/v1/embeddings',\n",
       "  'body': {'input': '[ê¸°ìì˜ ëˆˆ] ë²šê½ƒì—†ëŠ” ë²šê½ƒì¶•ì œ',\n",
       "   'model': 'text-embedding-3-small',\n",
       "   'encoding_format': 'float'}},\n",
       " {'custom_id': '1',\n",
       "  'method': 'POST',\n",
       "  'url': '/v1/embeddings',\n",
       "  'body': {'input': 'ì™¸ì‹ ë“¤,\"ì—”ë¹„ë””ì•„ ì  ìŠ¨í™©ì´ AIê³„ ìŠ¤í‹°ë¸Œ ì¡ìŠ¤\" í‰ê°€',\n",
       "   'model': 'text-embedding-3-small',\n",
       "   'encoding_format': 'float'}},\n",
       " {'custom_id': '2',\n",
       "  'method': 'POST',\n",
       "  'url': '/v1/embeddings',\n",
       "  'body': {'input': 'ë² íŠ¸ë‚¨ GDP 3% íš¡ë ¹í•œ ë¶€ë™ì‚° ì¬ë²Œâ€¦ì‚¬í˜• êµ¬í˜•',\n",
       "   'model': 'text-embedding-3-small',\n",
       "   'encoding_format': 'float'}},\n",
       " {'custom_id': '3',\n",
       "  'method': 'POST',\n",
       "  'url': '/v1/embeddings',\n",
       "  'body': {'input': '[ì‚¬ì„¤] â€œì •ê·œì§ ê³¼ë³´í˜¸ì— ì¤‘ì¥ë…„ ê³ ìš© ë¶ˆì•ˆâ€Â·Â·Â·ë…¸ë™ ìœ ì—°í™” ì„œë‘˜ëŸ¬ì•¼',\n",
       "   'model': 'text-embedding-3-small',\n",
       "   'encoding_format': 'float'}},\n",
       " {'custom_id': '4',\n",
       "  'method': 'POST',\n",
       "  'url': '/v1/embeddings',\n",
       "  'body': {'input': '[ì‚¬ì„¤] ì˜ëŒ€ë³„ ì •ì› í™•ì •, íŠ¹ìœ„ì—ì„œ í•„ìˆ˜?ì§€ì—­ ì˜ë£Œ ì •ìƒí™”ì— ë¨¸ë¦¬ ë§ëŒ€ë¼',\n",
       "   'model': 'text-embedding-3-small',\n",
       "   'encoding_format': 'float'}}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_jsonl[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save texts_jsonl to file\n",
    "text_jsonfile = os.path.join(base_dir,'news_texts.jsonl')\n",
    "with open(text_jsonfile, 'w', encoding='utf-8') as f:\n",
    "    for text in texts_jsonl:\n",
    "        jsonrec = json.dumps(text, ensure_ascii=False)\n",
    "        f.write(f'{jsonrec}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file = client.files.create(\n",
    "    file=open(text_jsonfile, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "batch_input_file_id = batch_input_file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = os.path.join(base_dir, 'news_embedding_response.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch embedding request\n",
    "batch_embedding_obj = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/embeddings\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"Embedding batch run\"\n",
    "    }\n",
    ")\n",
    "batch_id = batch_embedding_obj.id\n",
    "print(f\"Embedding Batch ID: {batch_embedding_obj.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNLOAD complete file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\by003457\\\\data\\\\ofij\\\\stock_meta_response.jsonl'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-12 13:03:26] Batch status: in_progress\n",
      "[2025-04-12 13:04:27] Batch status: in_progress\n",
      "[2025-04-12 13:05:27] Batch status: in_progress\n",
      "[2025-04-12 13:06:27] Batch status: in_progress\n",
      "[2025-04-12 13:07:27] Batch status: in_progress\n",
      "[2025-04-12 13:08:28] Batch status: in_progress\n",
      "[2025-04-12 13:09:28] Batch status: in_progress\n",
      "[2025-04-12 13:10:28] Batch status: in_progress\n",
      "[2025-04-12 13:11:28] Batch status: in_progress\n",
      "[2025-04-12 13:12:28] Batch status: in_progress\n",
      "[2025-04-12 13:13:29] Batch status: in_progress\n",
      "[2025-04-12 13:14:29] Batch status: in_progress\n",
      "[2025-04-12 13:15:29] Batch status: in_progress\n",
      "[2025-04-12 13:16:29] Batch status: in_progress\n",
      "[2025-04-12 13:17:30] Batch status: in_progress\n",
      "[2025-04-12 13:18:30] Batch status: in_progress\n",
      "[2025-04-12 13:19:30] Batch status: in_progress\n",
      "[2025-04-12 13:20:30] Batch status: in_progress\n",
      "[2025-04-12 13:21:31] Batch status: in_progress\n",
      "[2025-04-12 13:22:31] Batch status: in_progress\n",
      "[2025-04-12 13:23:31] Batch status: in_progress\n",
      "[2025-04-12 13:24:31] Batch status: in_progress\n",
      "[2025-04-12 13:25:32] Batch status: in_progress\n",
      "[2025-04-12 13:26:32] Batch status: in_progress\n",
      "[2025-04-12 13:27:32] Batch status: in_progress\n",
      "[2025-04-12 13:28:32] Batch status: in_progress\n",
      "[2025-04-12 13:29:32] Batch status: in_progress\n",
      "[2025-04-12 13:30:33] Batch status: in_progress\n",
      "[2025-04-12 13:31:33] Batch status: in_progress\n",
      "[2025-04-12 13:32:33] Batch status: in_progress\n",
      "[2025-04-12 13:33:33] Batch status: in_progress\n",
      "[2025-04-12 13:34:34] Batch status: in_progress\n",
      "[2025-04-12 13:35:34] Batch status: in_progress\n",
      "[2025-04-12 13:36:34] Batch status: in_progress\n",
      "[2025-04-12 13:37:34] Batch status: in_progress\n",
      "[2025-04-12 13:38:35] Batch status: in_progress\n",
      "[2025-04-12 13:39:35] Batch status: in_progress\n",
      "[2025-04-12 13:40:35] Batch status: in_progress\n",
      "[2025-04-12 13:41:35] Batch status: in_progress\n",
      "[2025-04-12 13:42:35] Batch status: in_progress\n",
      "[2025-04-12 13:43:36] Batch status: in_progress\n",
      "[2025-04-12 13:44:36] Batch status: in_progress\n",
      "[2025-04-12 13:45:36] Batch status: in_progress\n",
      "[2025-04-12 13:46:36] Batch status: in_progress\n",
      "[2025-04-12 13:47:37] Batch status: in_progress\n",
      "[2025-04-12 13:48:37] Batch status: finalizing\n",
      "[2025-04-12 13:49:37] Batch status: completed\n",
      "[2025-04-12 13:49:37] âœ… Batch completed successfully!\n",
      "[2025-04-12 13:49:38] âœ… Embedding results saved at: C:\\Users\\by003457\\data\\ofij\\stock_meta_response.jsonl\n",
      "[2025-04-12 13:49:38] ğŸ‰ Monitoring script finished.\n"
     ]
    }
   ],
   "source": [
    "POLL_INTERVAL = 60\n",
    "\n",
    "def timestamp():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "while True:\n",
    "    batch_status = client.batches.retrieve(batch_id)\n",
    "    current_status = batch_status.status\n",
    "    print(f\"[{timestamp()}] Batch status: {current_status}\")\n",
    "\n",
    "    if current_status == \"completed\":\n",
    "        print(f\"[{timestamp()}] âœ… Batch completed successfully!\")\n",
    "\n",
    "        output_file_id = batch_status.output_file_id\n",
    "        output_file = client.files.retrieve(output_file_id)\n",
    "\n",
    "        result = client.files.content(output_file_id)\n",
    "    \n",
    "        with open(output_filepath, \"wb\") as f:\n",
    "            f.write(result.content)\n",
    "        print(f\"[{timestamp()}] âœ… Embedding results saved at: {output_filepath}\")\n",
    "        break\n",
    "\n",
    "    elif current_status in {\"failed\", \"cancelled\", \"expired\"}:\n",
    "        print(f\"[{timestamp()}] âŒ Batch terminated with status: {current_status}. Please check logs on OpenAI's dashboard.\")\n",
    "        break\n",
    "\n",
    "    time.sleep(POLL_INTERVAL)\n",
    "\n",
    "print(f\"[{timestamp()}] ğŸ‰ Monitoring script finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-D5iNmWiRWZmzUhkGFrSxs3'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "resobj = []\n",
    "with open(output_filepath, 'r', encoding='utf-8') as f:\n",
    "\tfor line in f:\n",
    "\t\tresobj.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resobj[0]['custom_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-BLSwhtgUoIsOn1qyxRzHt887DgpxD',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1744455855,\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'ë™í™”ì•½í’ˆì€ ì¤‘ê·œëª¨ ì‹œê°€ì´ì•¡ì„ ê°€ì§„ ì˜ì•½í’ˆ ì œì¡°ì—…ì²´ë¡œ, ì˜ì•½í’ˆ ë¶„ì•¼ì— ì†í•˜ëŠ” ê¸°ì—…ì…ë‹ˆë‹¤.',\n",
       "    'refusal': None,\n",
       "    'annotations': []},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 88,\n",
       "  'completion_tokens': 33,\n",
       "  'total_tokens': 121,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': 'fp_44added55e'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resobj[0]['response']['body'] #['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
